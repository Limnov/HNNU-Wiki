# YOLO 模型性能

训练完成后，YOLO 会在 `runs/train/exp/` 目录下生成多张图表，帮助分析模型性能。

## 训练曲线 results.png

这是最重要的图表，包含 4 个子图：

### 损失曲线（Loss）

```
train/box_loss    - 边界框定位损失
train/cls_loss    - 分类损失
train/dfl_loss    - 分布式焦点损失

val/box_loss      - 验证集边界框损失
val/cls_loss      - 验证集分类损失
val/dfl_loss      - 验证集DFL损失
```

**如何判断：**
- ✅ 训练损失和验证损失都下降 → 正常
- ⚠️ 训练损失下降，验证损失上升 → 过拟合
- ⚠️ 两者都不下降 → 模型无法学习，检查数据

### 精确率与召回率（Precision & Recall）

```
metrics/precision(B) - 精确率
metrics/recall(B)    - 召回率
```

**含义：**
- **精确率**：预测为正例中有多少是正确的（少误报）
- **召回率**：实际正例中有多少被找出来（少漏报）

**如何判断：**
- 两者越高越好，理想状态都接近 1.0
- 精确率高召回率低 → 模型保守，漏检多
- 召回率高精确率低 → 模型激进，误报多

### mAP 曲线

```
metrics/mAP50(B)     - IoU=0.5 时的平均精度
metrics/mAP50-95(B)  - IoU从0.5到0.95的平均精度
```

**含义：**
- **mAP50**：较宽松的评估，更容易达到高分
- **mAP50-95**：更严格的评估，更能反映真实性能

**参考标准（COCO数据集）：**
| mAP50-95 | 水平 |
|----------|------|
| < 0.3 | 需要改进 |
| 0.3 - 0.5 | 一般 |
| 0.5 - 0.6 | 良好 |
| > 0.6 | 优秀 |

## 混淆矩阵 confusion_matrix.png

显示模型对每个类别的预测情况：

```
              预测
              猫   狗   背景
实际  猫     [50   5    3]
      狗     [ 2  45    8]
      背景   [ 1   2   40]
```

**如何看：**
- **对角线**：正确预测的数量（越大越好）
- **非对角线**：错误预测（混淆情况）
- 深色 = 数量多，浅色 = 数量少

**常见问题：**
- 某类总是被预测成另一类 → 两类特征相似，需要更多数据
- 很多被预测为背景 → 模型保守，可降低置信度阈值

## PR 曲线 PR_curve.png

精确率-召回率曲线：

```
精确率
  1.0 |●●●●
      |    ●●●
      |       ●●●
  0.5 |          ●●●
      |             ●●●
  0.0 |________________●●●
      0.0      召回率     1.0
```

**如何判断：**
- 曲线越靠近右上角越好
- 曲线下面积（AUC）越接近 1 越好

## F1 曲线 F1_curve.png

F1 分数是精确率和召回率的调和平均：

```
F1 = 2 × (精确率 × 召回率) / (精确率 + 召回率)
```

**如何判断：**
- F1 曲线的峰值对应最佳置信度阈值
- 曲线越平坦 → 模型对阈值不敏感

## 预测结果示例 val_batch*.jpg

显示验证集的实际预测效果：

- 绿色框 = 正确预测
- 红色框 = 错误预测
- 可以直观看到模型哪里预测对了/错了

## 常见问题诊断

### 过拟合

**症状：** 训练损失持续下降，验证损失上升或停滞

**解决方案：**
- 增加训练数据
- 使用数据增强
- 减小模型规模
- 增加 dropout
- 早停（patience 参数）

### 欠拟合

**症状：** 训练和验证损失都很高

**解决方案：**
- 增加训练轮数
- 使用更大的模型
- 降低正则化
- 检查数据标注是否正确

### 类别不平衡

**症状：** 某些类别 mAP 很低

**解决方案：**
- 平衡各类别数据量
- 使用 focal loss
- 对少数类过采样

## 性能评估代码

```python
from ultralytics import YOLO

model = YOLO('runs/train/exp/weights/best.pt')
metrics = model.val()

print(f"mAP50:    {metrics.box.map50:.4f}")
print(f"mAP50-95: {metrics.box.map:.4f}")
print(f"精确率:    {metrics.box.mp:.4f}")
print(f"召回率:    {metrics.box.mr:.4f}")

# 每个类别的 mAP
for i, ap in enumerate(metrics.box.ap):
    print(f"类别 {i} mAP: {ap:.4f}")
```

## 小结

| 图表 | 关注点 |
|------|--------|
| results.png | 整体训练趋势 |
| confusion_matrix.png | 类别混淆情况 |
| PR_curve.png | 精确率-召回率平衡 |
| F1_curve.png | 最佳置信度阈值 |
| val_batch*.jpg | 实际预测效果 |
